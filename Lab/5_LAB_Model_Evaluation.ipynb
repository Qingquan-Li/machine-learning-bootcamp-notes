{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX0KncWHz_qL"
      },
      "source": [
        "Name:  Qingquan Li  \n",
        "ID: 24263976"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUwAigtnzbVm"
      },
      "source": [
        "# Question-1\n",
        "Use Grid search to find the best parameters for the Iris data\n",
        "for the following ML Algortihms\n",
        "  - kNN Classifier\n",
        "  - Desicion Tree Classifier\n",
        "  - Random Forest Classifier\n",
        "\n",
        "- Choose at least 20 parameter combinations for each model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkdfrSp_z86x"
      },
      "source": [
        "# Solution-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTQNeVgyXBEf"
      },
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "dataset_iris = load_iris()\n",
        "X = dataset_iris.data\n",
        "y = dataset_iris.target"
      ],
      "metadata": {
        "id": "TDnlwRRUPlh7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TKa1oxc2Pnav"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for kNN Classifier\n",
        "knn_params = {\n",
        "    'n_neighbors': list(range(1, 11)),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "print(f\"Best Parameters for kNN: {knn_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmC9RPfjPp2m",
        "outputId": "4065b059-11a1-4d68-c30f-c6c5fc187f24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for kNN: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for Decision Tree Classifier\n",
        "dt_params = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': list(range(1, 11)),\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3]\n",
        "}\n",
        "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5)\n",
        "dt_grid.fit(X_train, y_train)\n",
        "print(f\"Best Parameters for Decision Tree: {dt_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5vHtrBbPtYj",
        "outputId": "b0dc946b-746c-431a-b3fa-75cd2acaec9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Decision Tree: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for Random Forest Classifier\n",
        "rf_params = {\n",
        "    # 'n_estimators': [10, 50, 100, 150],  # runs too long\n",
        "    'n_estimators': [1, 5, 10, 15],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': list(range(1, 11)),\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3]\n",
        "}\n",
        "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "print(f\"Best Parameters for Random Forest: {rf_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcoyHBa4PwOa",
        "outputId": "a00790fa-5911-45af-c62a-9e5ccbbebbfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Random Forest: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da4Pq_By0Ez0"
      },
      "source": [
        "# Question-2\n",
        "\n",
        "Use Grid search to find the best parameters for the California housing data for the following ML Algortihms\n",
        "  - kNN Regressor\n",
        "  - Decision Tree Regressor\n",
        "  - Random Forest Regressor\n",
        "- Choose at least 20 parameter combinations for each model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3dgYq-R0hls"
      },
      "source": [
        "# Solution-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTLKBuxlX9Nx"
      },
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "dataset_cal = fetch_california_housing()\n",
        "X = dataset_cal.data\n",
        "y = dataset_cal.target"
      ],
      "metadata": {
        "id": "_oZYzOP5P6qS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "QDC9nfFpP8m-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for kNN Regressor\n",
        "knn_params = {\n",
        "    'n_neighbors': list(range(1, 11)),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "}\n",
        "knn_grid = GridSearchCV(KNeighborsRegressor(), knn_params, cv=5)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "print(f\"Best Parameters for kNN Regressor: {knn_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-zkg7bKP_bi",
        "outputId": "82eaac78-5d11-4e4e-db3f-ead34f322f30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for kNN Regressor: {'algorithm': 'auto', 'n_neighbors': 8, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search for Decision Tree Regressor\n",
        "dt_params = {\n",
        "    'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': list(range(1, 11)),\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3]\n",
        "}\n",
        "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
        "dt_grid.fit(X_train, y_train)\n",
        "print(f\"Best Parameters for Decision Tree Regressor: {dt_grid.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__ICQH-8QB5g",
        "outputId": "fce045bb-3913-45e0-aad8-02521c4aa5ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for Decision Tree Regressor: {'criterion': 'poisson', 'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 4, 'splitter': 'best'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1800 fits failed out of a total of 3600.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "900 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'absolute_error', 'poisson', 'squared_error', 'friedman_mse'}. Got 'mse' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "900 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'absolute_error', 'poisson', 'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.31377468 0.20246302 0.31377468 0.10648139 0.31377468 0.27085624\n",
            " 0.31377468 0.07949652 0.31377468 0.17864399 0.31377468 0.14770654\n",
            " 0.31377468 0.09750402 0.31377468 0.11302408 0.31377468 0.16888785\n",
            " 0.44760888 0.26184936 0.44760888 0.28811735 0.44760888 0.22517931\n",
            " 0.44760888 0.17881864 0.44760888 0.29468759 0.44760888 0.28566072\n",
            " 0.44760888 0.2465471  0.44760888 0.30623134 0.44760888 0.26073709\n",
            " 0.53169343 0.41878109 0.53169343 0.35907342 0.53169343 0.21723492\n",
            " 0.53169343 0.32553776 0.53169343 0.33400246 0.53169343 0.34408013\n",
            " 0.53169343 0.38777931 0.53169343 0.39841802 0.53169343 0.26161634\n",
            " 0.57869915 0.44044497 0.57877507 0.33143562 0.57877507 0.37946211\n",
            " 0.57902106 0.42722865 0.57902106 0.45617641 0.57902106 0.35050194\n",
            " 0.57902106 0.41648042 0.57902106 0.40800857 0.57902106 0.39457028\n",
            " 0.61394669 0.45658147 0.61394669 0.46533219 0.61394669 0.43291052\n",
            " 0.61401889 0.49071444 0.61401889 0.46550129 0.61401889 0.46742866\n",
            " 0.61426531 0.46699887 0.61426531 0.46299272 0.61426531 0.46840482\n",
            " 0.64481035 0.51556783 0.64488223 0.50471536 0.6448238  0.5162902\n",
            " 0.6462377  0.52643554 0.64616687 0.51754697 0.6459246  0.5378835\n",
            " 0.64690743 0.51106646 0.64690743 0.51126506 0.64690743 0.5375095\n",
            " 0.66337963 0.55670817 0.66336173 0.53724333 0.66374371 0.5442678\n",
            " 0.66399885 0.55200721 0.66413567 0.55304084 0.66411738 0.47576084\n",
            " 0.66588172 0.5352734  0.66578408 0.53420427 0.66578408 0.53061911\n",
            " 0.67920254 0.59077593 0.68015735 0.56807048 0.67967708 0.5586614\n",
            " 0.68053077 0.58251854 0.67996462 0.55827099 0.67964757 0.56971996\n",
            " 0.68228813 0.5681351  0.68239431 0.56026031 0.68236481 0.5423489\n",
            " 0.68205422 0.61416869 0.68210277 0.60851268 0.68303145 0.5837348\n",
            " 0.68718852 0.59334974 0.68747392 0.59638438 0.68745863 0.60155918\n",
            " 0.69103302 0.58444173 0.69062544 0.58126785 0.69072592 0.58257326\n",
            " 0.67607825 0.59033414 0.67542536 0.61210761 0.67858331 0.61215972\n",
            " 0.6883441  0.61149484 0.68664946 0.61487393 0.68701468 0.63150667\n",
            " 0.69240327 0.62322881 0.69270821 0.63845187 0.6924424  0.5844492\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.29664402 0.14921514 0.29664402 0.10946062 0.29664402 0.22268057\n",
            " 0.29664402 0.16795912 0.29664402 0.17127589 0.29664402 0.15761012\n",
            " 0.29664402 0.18662347 0.29664402 0.18861053 0.29664402 0.13091958\n",
            " 0.44526647 0.25664969 0.44526647 0.23097992 0.44526647 0.17719555\n",
            " 0.44526647 0.2627859  0.44526647 0.34761041 0.44526647 0.33380094\n",
            " 0.44526647 0.18174341 0.44526647 0.29935197 0.44526647 0.14546406\n",
            " 0.53596647 0.38961874 0.53596647 0.35987452 0.53596647 0.41992268\n",
            " 0.53596647 0.2830431  0.53596647 0.35557764 0.53596647 0.36509194\n",
            " 0.53596647 0.27251191 0.53596647 0.39556429 0.53596647 0.2665979\n",
            " 0.57733562 0.43653385 0.57733562 0.41933491 0.57733562 0.42922616\n",
            " 0.57733562 0.41912752 0.57733562 0.42808698 0.57733562 0.44459396\n",
            " 0.57733562 0.41339451 0.57733562 0.38764988 0.57733562 0.37810805\n",
            " 0.61682119 0.48042405 0.61689712 0.49478782 0.61682119 0.48574002\n",
            " 0.61704466 0.46400602 0.61704466 0.45943037 0.61704466 0.4467393\n",
            " 0.61704466 0.44306701 0.61704466 0.49156681 0.61704466 0.49644247\n",
            " 0.64195813 0.52409189 0.64210833 0.54163205 0.64204288 0.51360455\n",
            " 0.64256006 0.47861778 0.64256006 0.51385453 0.64256006 0.51915585\n",
            " 0.64294256 0.49319625 0.64294256 0.53813463 0.64294256 0.52689613\n",
            " 0.66439997 0.5417264  0.66334618 0.53901523 0.66371669 0.5238132\n",
            " 0.66436387 0.533674   0.66472986 0.52296836 0.66496611 0.55616784\n",
            " 0.66580553 0.55306294 0.6658874  0.56828968 0.6658874  0.55817225\n",
            " 0.67908892 0.56808725 0.67969494 0.55931583 0.68103196 0.55879708\n",
            " 0.68065832 0.56866301 0.68070133 0.58766452 0.68030512 0.55732834\n",
            " 0.68209311 0.56344013 0.68249266 0.59166671 0.68247329 0.60663762\n",
            " 0.68803667 0.57416491 0.68636371 0.60031859 0.68761101 0.58598671\n",
            " 0.69209653 0.60992748 0.69236948 0.59110796 0.69113726 0.61286319\n",
            " 0.69279131 0.60637214 0.69344707 0.60183257 0.69348509 0.60135847\n",
            " 0.68128577 0.61901433 0.67944317 0.62751381 0.68089516 0.62186447\n",
            " 0.685019   0.5966378  0.68574881 0.62053424 0.68599343 0.60940407\n",
            " 0.6916169  0.61739207 0.69223419 0.61575923 0.69121509 0.60680497]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Grid search for Random Forest Regressor\n",
        "# rf_params = {\n",
        "#     'n_estimators': [10, 50, 100, 150],\n",
        "#     'criterion': ['mse', 'mae'],\n",
        "#     'max_depth': list(range(1, 11)),\n",
        "#     'min_samples_split': [2, 3, 4],\n",
        "#     'min_samples_leaf': [1, 2, 3]\n",
        "# }\n",
        "# rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
        "# rf_grid.fit(X_train, y_train)\n",
        "# print(f\"Best Parameters for Random Forest Regressor: {rf_grid.best_params_}\")"
      ],
      "metadata": {
        "id": "WjQ5KuhfS3b5"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}